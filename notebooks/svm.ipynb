{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import librosa, librosa.display\n",
    "import IPython.display as ipd\n",
    "from random import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import signal\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "PROCESSED_DATA_PICKLE_PATH = '../data/df_all.pkl'\n",
    "PROCESSED_DATA_PICKLE_PATH_N = '../data/df_normal.pkl'\n",
    "\n",
    "EMOTIONS = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']\n",
    "\n",
    "MFCC_LENGTH = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                path source actor gender  \\\n0  ../data/Audio_Speech_Actors_01-24/Actor_01/03-...      1     1      1   \n1  ../data/Audio_Speech_Actors_01-24/Actor_01/03-...      1     1      1   \n2  ../data/Audio_Speech_Actors_01-24/Actor_01/03-...      1     1      1   \n3  ../data/Audio_Speech_Actors_01-24/Actor_01/03-...      1     1      1   \n4  ../data/Audio_Speech_Actors_01-24/Actor_01/03-...      1     1      1   \n\n  gender_label statement repetition intensity emotion emotion_label  \\\n0         male         0          1         0       0       neutral   \n1         male         0          2         0       0       neutral   \n2         male         1          1         0       0       neutral   \n3         male         1          2         0       0       neutral   \n4         male         0          1         0       1          calm   \n\n                                                mfcc  \n0  [[-857.3094533443688, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n1  [[-864.8902862773604, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n2  [[-849.4454325616318, 9.397479238778757, 9.257...  \n3  [[-832.7343966188961, 11.492822043371124, 0.14...  \n4  [[-902.4064116162402, 6.517241898027468, 6.427...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>source</th>\n      <th>actor</th>\n      <th>gender</th>\n      <th>gender_label</th>\n      <th>statement</th>\n      <th>repetition</th>\n      <th>intensity</th>\n      <th>emotion</th>\n      <th>emotion_label</th>\n      <th>mfcc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../data/Audio_Speech_Actors_01-24/Actor_01/03-...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>male</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>neutral</td>\n      <td>[[-857.3094533443688, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../data/Audio_Speech_Actors_01-24/Actor_01/03-...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>male</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>neutral</td>\n      <td>[[-864.8902862773604, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../data/Audio_Speech_Actors_01-24/Actor_01/03-...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>male</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>neutral</td>\n      <td>[[-849.4454325616318, 9.397479238778757, 9.257...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../data/Audio_Speech_Actors_01-24/Actor_01/03-...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>male</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>neutral</td>\n      <td>[[-832.7343966188961, 11.492822043371124, 0.14...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../data/Audio_Speech_Actors_01-24/Actor_01/03-...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>male</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>calm</td>\n      <td>[[-902.4064116162402, 6.517241898027468, 6.427...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(PROCESSED_DATA_PICKLE_PATH)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                path source actor gender  \\\n0  ../data/Audio_Speech_Actors_01-24/Actor_01/03-...      1     1      1   \n1  ../data/Audio_Speech_Actors_01-24/Actor_01/03-...      1     1      1   \n2  ../data/Audio_Speech_Actors_01-24/Actor_01/03-...      1     1      1   \n3  ../data/Audio_Speech_Actors_01-24/Actor_01/03-...      1     1      1   \n4  ../data/Audio_Speech_Actors_01-24/Actor_01/03-...      1     1      1   \n\n  gender_label statement repetition intensity emotion emotion_label  \\\n0         male         0          1         0       0       neutral   \n1         male         0          2         0       0       neutral   \n2         male         1          1         0       0       neutral   \n3         male         1          2         0       0       neutral   \n4         male         0          1         0       1          calm   \n\n  augmentation mfcc  \n0         none       \n1         none       \n2         none       \n3         none       \n4         none       ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>source</th>\n      <th>actor</th>\n      <th>gender</th>\n      <th>gender_label</th>\n      <th>statement</th>\n      <th>repetition</th>\n      <th>intensity</th>\n      <th>emotion</th>\n      <th>emotion_label</th>\n      <th>augmentation</th>\n      <th>mfcc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../data/Audio_Speech_Actors_01-24/Actor_01/03-...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>male</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>neutral</td>\n      <td>none</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../data/Audio_Speech_Actors_01-24/Actor_01/03-...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>male</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>neutral</td>\n      <td>none</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../data/Audio_Speech_Actors_01-24/Actor_01/03-...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>male</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>neutral</td>\n      <td>none</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../data/Audio_Speech_Actors_01-24/Actor_01/03-...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>male</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>neutral</td>\n      <td>none</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../data/Audio_Speech_Actors_01-24/Actor_01/03-...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>male</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>calm</td>\n      <td>none</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal = pd.read_pickle(PROCESSED_DATA_PICKLE_PATH_N)\n",
    "df_normal.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    df = pd.read_pickle(data_path)\n",
    "\n",
    "    # clean up data\n",
    "    vals = []\n",
    "    for i, val in enumerate(df[\"mfcc\"].to_numpy()):\n",
    "        if len(val) < MFCC_LENGTH:\n",
    "            vals.append(i)\n",
    "\n",
    "    df = df.drop(vals)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    X = np.stack(df[\"mfcc\"].to_numpy())\n",
    "    y = np.stack(df[\"emotion\"].to_numpy())\n",
    "\n",
    "    return X, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def prepare_datasets(test_size):\n",
    "\n",
    "    # load data\n",
    "    X, y = load_data(PROCESSED_DATA_PICKLE_PATH)\n",
    "\n",
    "    new_X = []\n",
    "    for i in X:\n",
    "        avg_mfcc = []\n",
    "        for j in i:\n",
    "            avg_mfcc.append(j.mean())\n",
    "        new_X.append(avg_mfcc)\n",
    "    X = np.array(new_X)\n",
    "\n",
    "    # create train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepare_datasets(0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(432, 125)\n",
      "Accuracy: 0.3148148148148148\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(X_test.shape)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: {}\".format(metrics.accuracy_score(y_test, y_pred)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}